{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Connector Starter - Document Portal Example\n",
    "This starter walks through the basics for developing a custom connector that pushes documents to the Glean index. It assumes that a customer has a document portal where employees go to find, read, and download documents.  For example: company policies, design documents, benefits documents.  \n",
    "\n",
    "As a starter, it doesn't address some of the more advanced topics like robust error handling, API endpoint retries, cleanup, and multi-timescale scheduling.  The goal is to enable developers to get started quickly and demonstrate feasibility. For educational purposes, this starter calls Glean REST API endpoints directly without using an SDK. For larger scale custom connectors, it is recommended to use the [Glean indexing API client](https://developers.glean.com/docs/sdk/readme/).\n",
    "\n",
    "## References\n",
    "\n",
    "* [Glean Indexing API Getting Started](https://developers.glean.com/docs/indexing_api/indexing_api_getting_started/)\n",
    "* [Get Datasource Config](https://developers.glean.com/indexing/tag/Datasources/paths/~1getdatasourceconfig/post/)\n",
    "* [Bulk Index Documents](https://developers.glean.com/indexing/tag/Documents/paths/~1bulkindexdocuments/post/)\n",
    "* [Index Document](https://developers.glean.com/indexing/tag/Documents/paths/~1indexdocument/post/)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* We assume you are familiar with Python, setting up virtual environments, and installing requirements via a requirements.txt file.\n",
    "* We assume that you have Jupyter Notebook working in VS Code. To learn more about Jupyter Notebook in VS Code, check out [this page](https://code.visualstudio.com/docs/datascience/jupyter-notebooks).\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "### Create Custom Connector Configuration\n",
    "The following are a minimal set of instructions for creating the custom connector configuration.\n",
    "\n",
    "* Go to [data sources](https://app.glean.com/admin/setup/apps) in the Glean admin panel.\n",
    "* Select \"Add data source\" and select \"Custom\", which is found at the bottom of the list.\n",
    "* Fill in the following fields:\n",
    "  * Data source basics\n",
    "    * Unique name: [your choice, no spaces or underscores]\n",
    "    * Data source category: Published Content\n",
    "    * URL regex: [a regex expression that matches your document portal, e.g., https://myportal.com/.*]\n",
    "    * Toggle on the \"Email is used to reference...\" option\n",
    "  * Object definitions\n",
    "    * Add an object type\n",
    "    * Category: Published Content\n",
    "    * Name: [e.g., Policy]\n",
    "* Select Publish\n",
    "\n",
    "## Set Visibility\n",
    "Go to the connector configuration overview and turn on visibility, so that search results will show up.\n",
    "\n",
    "### Generate indexing API token\n",
    "You must create an indexing API token to use Glean's indexing API endpoints.\n",
    "\n",
    "* Go to [Indexing API Tokens](https://app.glean.com/admin/platform/tokenManagement?tab=indexing)\n",
    "* Select \"Add token\"\n",
    "* Fill in the following fields:\n",
    "  * Description\n",
    "  * Scopes\n",
    "    * Leave \"Has Global permissions\" off.\n",
    "    * Enter the same name you used above as the unique name for your data source.\n",
    "  * Expiration\n",
    "* Select \"Save\"\n",
    "* Copy/paste the token into your .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "The starter uses a minimal set of dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, base64, datetime, uuid, logging\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# this is the name of your custom datasource\n",
    "datasource_name = 'mydocumentportal'\n",
    "\n",
    "# this is the name of the object type you used for the custom datasource\n",
    "object_type = 'policy'\n",
    "\n",
    "# toggle to turn on bulk indexing\n",
    "bulk_index_flag = True\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env', override=True)\n",
    "\n",
    "# Get the document portal environment variables (the examples below are just placeholders)\n",
    "DOCUMENT_PORTAL_URL = os.getenv('DOCUMENT_PORTAL_URL')\n",
    "DOCUMENT_PORTAL_API_KEY = os.getenv('DOCUMENT_PORTAL_API_KEY')\n",
    "\n",
    "# Get the Glean environment variables\n",
    "GLEAN_API_KEY = os.getenv('GLEAN_API_KEY')\n",
    "GLEAN_PROJECT_ID = os.getenv('GLEAN_PROJECT_ID')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, 'INFO', logging.INFO), \n",
    "    format='(%(levelname)s) %(asctime)s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S', \n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "These are some helpful utility functions. They aren't necessary, but we've found them to be helpful. Depending on your data, you may need to tweak them to work appropriately.  For example, the datetime string format is hard-coded, which may not align with your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_raw_binary_to_base64_string(raw_binary):\n",
    "    \"\"\"Converts raw binary data to a base64 string.\"\"\"\n",
    "    return base64.b64encode(raw_binary).decode('utf-8')\n",
    "\n",
    "def convert_timestamp_to_epoch_seconds(datetime_str:str) -> int :\n",
    "    \"\"\"Converts a datetime string to epoch seconds as an int.\"\"\"\n",
    "    datetime_obj = datetime.datetime.strptime(datetime_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    return int(datetime_obj.timestamp())\n",
    "\n",
    "def create_batches(lst, batch_size):\n",
    "    \"\"\"Yield successive batches from a list. Useful for bulk processing.\"\"\"\n",
    "    for i in range(0, len(lst), batch_size):\n",
    "        yield lst[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull - Transform - Push\n",
    "The example will take a pull, transform, push approach for the custom connector.  It will pull all of the documents' meta-data and data, transform the meta-data and data to match the Glean REST API format, and push the documents in bulk to the Glean index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Documents\n",
    "This section is up to you to figure out.  The gist is: Use the document portal's API to get meta-data and document contents for each document that you want indexed. \n",
    "\n",
    "We'll provide a pretend example by reading a couple PDF files stored in the repository.  You can use this as a simple baseline to understand the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "### ----- Replace the following with your own code to get your documents ----- ###\n",
    "\n",
    "# Read pdf files and add them to the documents list\n",
    "for file in os.listdir('sample-docs'):\n",
    "    if file.endswith('.pdf'):\n",
    "        with open(f'sample-docs/{file}', 'rb') as f:\n",
    "            documents.append({\n",
    "                'binary_content': f.read(),\n",
    "                'url': f'https://mywebsite.com/files/{file}',\n",
    "                'filename': file,\n",
    "                'author': 'John Doe',\n",
    "                'authorEmail': 'john.doe@acme.com',\n",
    "                'title': 'Sample Document',\n",
    "                'date_created': '2024-12-15T03:05:58Z',\n",
    "                'id': file\n",
    "            })\n",
    "\n",
    "logging.info(f\"Pulled {len(documents)} documents from the document portal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Modify the following to align with the structure of your documents ----- ###\n",
    "def transform_document(document):\n",
    "    return {\n",
    "        # Minimum recommended fields\n",
    "        'datasource': datasource_name,\n",
    "        'id': document['id'],\n",
    "        'objectType': object_type,\n",
    "        'viewURL': document['url'],\n",
    "        'permissions': {\n",
    "            'allowAnonymousAccess': True\n",
    "        },\n",
    "        'title': document['title'],\n",
    "        'body': {\n",
    "            'mimeType': 'application/pdf',\n",
    "            'binaryContent': convert_raw_binary_to_base64_string(document['binary_content'])\n",
    "        },\n",
    "\n",
    "        # Optional - Comment out if not available\n",
    "        'author': {\n",
    "            'email': document['authorEmail'],\n",
    "            'name': document['author']\n",
    "        },\n",
    "        'createdAt': convert_timestamp_to_epoch_seconds(document['date_created'])\n",
    "\n",
    "        # There are several other fields you can add to the document object.\n",
    "        # Check the Glean API documentation for more information.\n",
    "    }\n",
    "\n",
    "# Transform the documents\n",
    "transformed_documents = [transform_document(document) for document in documents]\n",
    "\n",
    "logging.info(f\"Transformed {len(transformed_documents)} documents for indexing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Documents\n",
    "The code below shows two ways to index documents: bulk and individual.\n",
    "\n",
    "* Bulk indexing completely replaces the documents in the index for the given data source. \n",
    "* Individual indexing adds or updates documents one at a time.\n",
    "* There is another endpoint available which can add/update multiple documents at a time. It is subject to rate limiting of approximately 10 documents per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glean_api_base = f\"https://{GLEAN_PROJECT_ID}-be.glean.com/api/index/v1\"\n",
    "glean_headers = {\n",
    "    'Authorization': 'Bearer ' + GLEAN_API_KEY,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "if bulk_index_flag : \n",
    "    endpoint = f'{glean_api_base}/bulkindexdocuments'\n",
    "    index_id = str(uuid.uuid4())\n",
    "    data = {\n",
    "        \"uploadId\": index_id,\n",
    "        \"isFirstPage\": True,\n",
    "        \"isLastPage\": False,\n",
    "        \"forceRestartUpload\": True,        # specify when isFirstPage = True\n",
    "        \"datasource\": datasource_name,\n",
    "        \"documents\": [],\n",
    "    }\n",
    "    batches = list(create_batches(transformed_documents, batch_size))\n",
    "    n = len(batches)\n",
    "    for idx, batch in enumerate(batches):\n",
    "        data['documents'] = batch\n",
    "        data['isLastPage'] = idx == n - 1\n",
    "        \n",
    "        # Push the batch of documents to the Glean index\n",
    "        response = requests.post(endpoint, headers=glean_headers, json=data)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            logging.info(f'Batch {idx + 1}/{n} uploaded. Status code: {response.status_code}')\n",
    "        else:\n",
    "            logging.error(f'Batch {idx + 1}/{n} failed to upload. Status code: {response.status_code}')\n",
    "            logging.error(response.text)\n",
    "            raise RuntimeError('Failed to upload batch')\n",
    "        \n",
    "        if idx == 0:\n",
    "            data[\"isFirstPage\"] = False\n",
    "            data.pop('forceRestartUpload')\n",
    "\n",
    "else :\n",
    "    endpoint = f'{glean_api_base}/indexdocument'\n",
    "\n",
    "    for document in transformed_documents:\n",
    "        \n",
    "        # Push the document to the Glean index\n",
    "        response = requests.post(endpoint, headers=glean_headers, json={\"document\":document})\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            logging.info(f'Document {document[\"id\"]} uploaded. Status code: {response.status_code}')\n",
    "        else:\n",
    "            logging.error(f'Document {document[\"id\"]} failed to upload. Status code: {response.status_code}')\n",
    "            logging.error(response.text)\n",
    "            raise RuntimeError('Failed to upload document')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
